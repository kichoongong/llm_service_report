"""
LangGraph ê¸°ë°˜ Corrective RAG Agent
"""

import json
from datetime import datetime
from typing import Dict, Any, Literal
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma

from main import CorrectiveRAGState, CorrectionStep


class LangGraphCorrectiveRAG:
    """LangGraph ê¸°ë°˜ Corrective RAG Agent"""

    def __init__(self, vector_db: Chroma, llm: ChatOpenAI, max_iterations: int = 3):
        self.vector_db = vector_db
        self.llm = llm
        self.max_iterations = max_iterations

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤ ì„¤ì •
        self._setup_prompts()

        # ê·¸ë˜í”„ êµ¬ì„±
        self.graph = self._build_graph()

    def _setup_prompts(self):
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤ì„ ì„¤ì •í•©ë‹ˆë‹¤."""

        # 1. ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸
        self.analysis_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    """ë‹¹ì‹ ì€ ìë™ì°¨ ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„
2. í•„ìš”í•œ ì •ë³´ ìœ í˜• (ê¸°ëŠ¥ ì„¤ëª…, ì¡°ì‘ ë°©ë²•, ì£¼ì˜ì‚¬í•­ ë“±)
3. ê²€ìƒ‰í•´ì•¼ í•  í‚¤ì›Œë“œ
4. ì˜ˆìƒë˜ëŠ” ë‹µë³€ ë³µì¡ë„ (ë‹¨ìˆœ/ì¤‘ê°„/ë³µì¡)

ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "intent": "ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„",
    "info_type": "í•„ìš”í•œ ì •ë³´ ìœ í˜•",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
    "complexity": "ë‹¨ìˆœ/ì¤‘ê°„/ë³µì¡",
    "expected_sections": ["ì˜ˆìƒ ì„¹ì…˜1", "ì˜ˆìƒ ì„¹ì…˜2"]
}}""",
                ),
                ("human", "{question}"),
            ]
        )

        # 2. ì»¨í…ìŠ¤íŠ¸ ê°œì„  í”„ë¡¬í”„íŠ¸
        self.context_refinement_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    """ë‹¤ìŒì€ ìë™ì°¨ ë§¤ë‰´ì–¼ì—ì„œ ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤. 
ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì´ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ê°œì„ í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
1. ì»¨í…ìŠ¤íŠ¸ì˜ ê´€ë ¨ì„± í‰ê°€
2. ë¶€ì¡±í•œ ì •ë³´ ì‹ë³„
3. ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ í‚¤ì›Œë“œ ì œì•ˆ
4. ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±

ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.""",
                ),
                ("human", "ì§ˆë¬¸: {question}\nì»¨í…ìŠ¤íŠ¸: {context}"),
            ]
        )

        # 3. ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸
        self.answer_generation_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    """ë‹¹ì‹ ì€ ìë™ì°¨ ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‘ì„± ê°€ì´ë“œë¼ì¸:
1. ì •í™•ì„±: ë§¤ë‰´ì–¼ì˜ ì •ë³´ë¥¼ ì •í™•íˆ ë°˜ì˜
2. ëª…í™•ì„±: ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
3. ì™„ì „ì„±: ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€
4. ì•ˆì „ì„±: ì•ˆì „ ê´€ë ¨ ì •ë³´ëŠ” ê°•ì¡°
5. êµ¬ì¡°í™”: ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ì„±

ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:""",
                ),
                ("human", "ì§ˆë¬¸: {question}\nì»¨í…ìŠ¤íŠ¸: {context}"),
            ]
        )

        # 4. ë‹µë³€ ê²€ì¦ í”„ë¡¬í”„íŠ¸
        self.correction_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    """ë‹¹ì‹ ì€ ë‹µë³€ í’ˆì§ˆ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ë‹µë³€ì„ ê²€í† í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

ê²€í†  ê¸°ì¤€:
1. ì •í™•ì„±: ì •ë³´ê°€ ì˜¬ë°”ë¥¸ê°€?
2. ì™„ì „ì„±: ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µí–ˆëŠ”ê°€?
3. ëª…í™•ì„±: ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
4. ì¼ê´€ì„±: ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ëœê°€?
5. ì•ˆì „ì„±: ì•ˆì „ ê´€ë ¨ ì •ë³´ê°€ ì ì ˆíˆ í¬í•¨ë˜ì—ˆëŠ”ê°€?

ê²€í†  ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "is_correct": true/false,
    "confidence": 0.0-1.0,
    "issues": ["ë¬¸ì œì 1", "ë¬¸ì œì 2"],
    "improvements": ["ê°œì„ ì‚¬í•­1", "ê°œì„ ì‚¬í•­2"],
    "corrected_answer": "ìˆ˜ì •ëœ ë‹µë³€"
}}""",
                ),
                ("human", "ì§ˆë¬¸: {question}\në‹µë³€: {answer}\nì»¨í…ìŠ¤íŠ¸: {context}"),
            ]
        )

    def _build_graph(self) -> StateGraph:
        """LangGraph ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""

        # ê·¸ë˜í”„ ìƒì„±
        workflow = StateGraph(CorrectiveRAGState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("analyze_question", self._analyze_question_node)
        workflow.add_node("search_context", self._search_context_node)
        workflow.add_node("refine_context", self._refine_context_node)
        workflow.add_node("generate_answer", self._generate_answer_node)
        workflow.add_node("validate_answer", self._validate_answer_node)

        # ì‹œì‘ì  ì„¤ì •
        workflow.set_entry_point("analyze_question")

        # ì—£ì§€ ì¶”ê°€
        workflow.add_edge("analyze_question", "search_context")

        # ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ì»¨í…ìŠ¤íŠ¸ ê°œì„  ì—¬ë¶€
        workflow.add_conditional_edges(
            "search_context",
            self._should_refine_route,
            {"refine": "refine_context", "generate": "generate_answer"},
        )

        workflow.add_edge("refine_context", "generate_answer")
        workflow.add_edge("generate_answer", "validate_answer")

        # ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ê³„ì† ì§„í–‰ ì—¬ë¶€
        workflow.add_conditional_edges(
            "validate_answer",
            self._should_continue_route,
            {"continue": "analyze_question", "end": END},  # ë‹¤ì‹œ ë¶„ì„ë¶€í„° ì‹œì‘
        )

        return workflow.compile()

    def _analyze_question_node(self, state: CorrectiveRAGState) -> CorrectiveRAGState:
        """ì§ˆë¬¸ ë¶„ì„ ë…¸ë“œ"""
        print(f"ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘: {state['question']}")

        try:
            # ì§ˆë¬¸ ë¶„ì„
            analysis_chain = (
                ChatPromptTemplate.from_messages(
                    [
                        (
                            "system",
                            """ë‹¹ì‹ ì€ ìë™ì°¨ ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„
2. í•„ìš”í•œ ì •ë³´ ìœ í˜• (ê¸°ëŠ¥ ì„¤ëª…, ì¡°ì‘ ë°©ë²•, ì£¼ì˜ì‚¬í•­ ë“±)
3. ê²€ìƒ‰í•´ì•¼ í•  í‚¤ì›Œë“œ
4. ì˜ˆìƒë˜ëŠ” ë‹µë³€ ë³µì¡ë„ (ë‹¨ìˆœ/ì¤‘ê°„/ë³µì¡)

ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "intent": "ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„",
    "info_type": "í•„ìš”í•œ ì •ë³´ ìœ í˜•",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
    "complexity": "ë‹¨ìˆœ/ì¤‘ê°„/ë³µì¡",
    "expected_sections": ["ì˜ˆìƒ ì„¹ì…˜1", "ì˜ˆìƒ ì„¹ì…˜2"]
}}""",
                        ),
                        ("human", "{question}"),
                    ]
                )
                | self.llm
                | StrOutputParser()
            )
            analysis_result = analysis_chain.invoke({"question": state["question"]})

            # JSON íŒŒì‹±
            analysis = json.loads(analysis_result)

            # ìˆ˜ì • ë‹¨ê³„ ê¸°ë¡
            step = CorrectionStep(
                step_number=len(state.get("correction_steps", [])) + 1,
                action="analyze",
                description="ì§ˆë¬¸ ë¶„ì„",
                result=analysis_result,
                confidence=0.9,
                timestamp=datetime.now().isoformat(),
            )

            return {
                **state,
                "analysis": analysis,
                "keywords": analysis.get("keywords", [state["question"]]),
                "complexity": analysis.get("complexity", "ë‹¨ìˆœ"),
                "correction_steps": state.get("correction_steps", []) + [step.__dict__],
                "messages": state.get("messages", [])
                + [HumanMessage(content=f"ì§ˆë¬¸ ë¶„ì„: {state['question']}")],
            }

        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                **state,
                "analysis": {
                    "intent": "ì¼ë°˜ì ì¸ ì§ˆë¬¸",
                    "keywords": [state["question"]],
                    "complexity": "ë‹¨ìˆœ",
                },
                "keywords": [state["question"]],
                "complexity": "ë‹¨ìˆœ",
                "error_message": str(e),
            }

    def _search_context_node(self, state: CorrectiveRAGState) -> CorrectiveRAGState:
        """ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë…¸ë“œ"""
        print(f"ğŸ” ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘...")

        try:
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            keywords = state.get("keywords", [state["question"]])
            search_query = " ".join(keywords)

            # ë²¡í„° ê²€ìƒ‰
            search_results = self.vector_db.similarity_search(search_query, k=5)

            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []
            for i, result in enumerate(search_results):
                context_parts.append(f"[ë¬¸ì„œ {i+1}]\n{result.page_content}")

            context = "\n\n".join(context_parts)

            # ìˆ˜ì • ë‹¨ê³„ ê¸°ë¡
            step = CorrectionStep(
                step_number=len(state.get("correction_steps", [])) + 1,
                action="search",
                description="ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰",
                result=f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(search_results)}ê°œ",
                confidence=0.8,
                timestamp=datetime.now().isoformat(),
            )

            return {
                **state,
                "search_results": search_results,
                "context": context,
                "correction_steps": state.get("correction_steps", []) + [step.__dict__],
                "messages": state.get("messages", [])
                + [
                    AIMessage(
                        content=f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ë¬¸ì„œ"
                    )
                ],
            }

        except Exception as e:
            print(f"âŒ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                **state,
                "search_results": [],
                "context": "ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "error_message": str(e),
            }

    def _refine_context_node(self, state: CorrectiveRAGState) -> CorrectiveRAGState:
        """ì»¨í…ìŠ¤íŠ¸ ê°œì„  ë…¸ë“œ"""
        print(f"ğŸ”§ ì»¨í…ìŠ¤íŠ¸ ê°œì„  ì¤‘...")

        try:
            # ì»¨í…ìŠ¤íŠ¸ ê°œì„ 
            refinement_chain = (
                ChatPromptTemplate.from_messages(
                    [
                        (
                            "system",
                            """ë‹¤ìŒì€ ìë™ì°¨ ë§¤ë‰´ì–¼ì—ì„œ ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤. 
ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì´ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ê°œì„ í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
1. ì»¨í…ìŠ¤íŠ¸ì˜ ê´€ë ¨ì„± í‰ê°€
2. ë¶€ì¡±í•œ ì •ë³´ ì‹ë³„
3. ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ í‚¤ì›Œë“œ ì œì•ˆ
4. ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±

ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.""",
                        ),
                        ("human", "ì§ˆë¬¸: {question}\nì»¨í…ìŠ¤íŠ¸: {context}"),
                    ]
                )
                | self.llm
                | StrOutputParser()
            )
            refined_context = refinement_chain.invoke(
                {"question": state["question"], "context": state["context"]}
            )

            # ìˆ˜ì • ë‹¨ê³„ ê¸°ë¡
            step = CorrectionStep(
                step_number=len(state.get("correction_steps", [])) + 1,
                action="refine",
                description="ì»¨í…ìŠ¤íŠ¸ ê°œì„ ",
                result=f"ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(refined_context)}ì",
                confidence=0.8,
                timestamp=datetime.now().isoformat(),
            )

            return {
                **state,
                "refined_context": refined_context,
                "correction_steps": state.get("correction_steps", []) + [step.__dict__],
                "messages": state.get("messages", [])
                + [AIMessage(content="ì»¨í…ìŠ¤íŠ¸ ê°œì„  ì™„ë£Œ")],
            }

        except Exception as e:
            print(f"âŒ ì»¨í…ìŠ¤íŠ¸ ê°œì„  ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                **state,
                "refined_context": state["context"],
                "error_message": str(e),
            }

    def _generate_answer_node(self, state: CorrectiveRAGState) -> CorrectiveRAGState:
        """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
        print(f"ğŸ’­ ë‹µë³€ ìƒì„± ì¤‘...")

        try:
            # ë‹µë³€ ìƒì„±
            answer_chain = (
                ChatPromptTemplate.from_messages(
                    [
                        (
                            "system",
                            """ë‹¹ì‹ ì€ ìë™ì°¨ ë§¤ë‰´ì–¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‘ì„± ê°€ì´ë“œë¼ì¸:
1. ì •í™•ì„±: ë§¤ë‰´ì–¼ì˜ ì •ë³´ë¥¼ ì •í™•íˆ ë°˜ì˜
2. ëª…í™•ì„±: ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
3. ì™„ì „ì„±: ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€
4. ì•ˆì „ì„±: ì•ˆì „ ê´€ë ¨ ì •ë³´ëŠ” ê°•ì¡°
5. êµ¬ì¡°í™”: ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ì„±

ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:""",
                        ),
                        ("human", "ì§ˆë¬¸: {question}\nì»¨í…ìŠ¤íŠ¸: {context}"),
                    ]
                )
                | self.llm
                | StrOutputParser()
            )
            answer = answer_chain.invoke(
                {"question": state["question"], "context": state["refined_context"]}
            )

            # ìˆ˜ì • ë‹¨ê³„ ê¸°ë¡
            step = CorrectionStep(
                step_number=len(state.get("correction_steps", [])) + 1,
                action="generate",
                description="ë‹µë³€ ìƒì„±",
                result=f"ë‹µë³€ ê¸¸ì´: {len(answer)}ì",
                confidence=0.7,
                timestamp=datetime.now().isoformat(),
            )

            return {
                **state,
                "answer": answer,
                "correction_steps": state.get("correction_steps", []) + [step.__dict__],
                "messages": state.get("messages", [])
                + [AIMessage(content=f"ë‹µë³€ ìƒì„± ì™„ë£Œ: {answer[:100]}...")],
            }

        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                **state,
                "answer": "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "error_message": str(e),
            }

    def _validate_answer_node(self, state: CorrectiveRAGState) -> CorrectiveRAGState:
        """ë‹µë³€ ê²€ì¦ ë…¸ë“œ"""
        print(f"âœ… ë‹µë³€ ê²€ì¦ ì¤‘...")

        try:
            # ë‹µë³€ ê²€ì¦
            correction_chain = (
                ChatPromptTemplate.from_messages(
                    [
                        (
                            "system",
                            """ë‹¹ì‹ ì€ ë‹µë³€ í’ˆì§ˆ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ë‹µë³€ì„ ê²€í† í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

ê²€í†  ê¸°ì¤€:
1. ì •í™•ì„±: ì •ë³´ê°€ ì˜¬ë°”ë¥¸ê°€?
2. ì™„ì „ì„±: ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µí–ˆëŠ”ê°€?
3. ëª…í™•ì„±: ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
4. ì¼ê´€ì„±: ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ëœê°€?
5. ì•ˆì „ì„±: ì•ˆì „ ê´€ë ¨ ì •ë³´ê°€ ì ì ˆíˆ í¬í•¨ë˜ì—ˆëŠ”ê°€?

ê²€í†  ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "is_correct": true/false,
    "confidence": 0.0-1.0,
    "issues": ["ë¬¸ì œì 1", "ë¬¸ì œì 2"],
    "improvements": ["ê°œì„ ì‚¬í•­1", "ê°œì„ ì‚¬í•­2"],
    "corrected_answer": "ìˆ˜ì •ëœ ë‹µë³€"
}}""",
                        ),
                        (
                            "human",
                            "ì§ˆë¬¸: {question}\në‹µë³€: {answer}\nì»¨í…ìŠ¤íŠ¸: {context}",
                        ),
                    ]
                )
                | self.llm
                | StrOutputParser()
            )
            correction_result = correction_chain.invoke(
                {
                    "question": state["question"],
                    "answer": state["answer"],
                    "context": state["refined_context"],
                }
            )

            # JSON íŒŒì‹±
            correction_data = json.loads(correction_result)

            is_correct = correction_data.get("is_correct", True)
            confidence = correction_data.get("confidence", 0.5)
            corrected_answer = correction_data.get("corrected_answer", state["answer"])
            issues = correction_data.get("issues", [])
            improvements = correction_data.get("improvements", [])

            # ìˆ˜ì • ë‹¨ê³„ ê¸°ë¡
            step = CorrectionStep(
                step_number=len(state.get("correction_steps", [])) + 1,
                action="validate",
                description="ë‹µë³€ ê²€ì¦",
                result=f"ì •í™•ì„±: {is_correct}, ì‹ ë¢°ë„: {confidence:.2f}",
                confidence=confidence,
                timestamp=datetime.now().isoformat(),
            )

            return {
                **state,
                "corrected_answer": corrected_answer,
                "is_correct": is_correct,
                "confidence": confidence,
                "issues": issues,
                "improvements": improvements,
                "correction_steps": state.get("correction_steps", []) + [step.__dict__],
                "messages": state.get("messages", [])
                + [AIMessage(content=f"ë‹µë³€ ê²€ì¦ ì™„ë£Œ - ì‹ ë¢°ë„: {confidence:.2f}")],
            }

        except Exception as e:
            print(f"âŒ ë‹µë³€ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                **state,
                "corrected_answer": state["answer"],
                "is_correct": True,
                "confidence": 0.5,
                "issues": [],
                "improvements": [],
                "error_message": str(e),
            }

    def _should_refine_route(
        self, state: CorrectiveRAGState
    ) -> Literal["refine", "generate"]:
        """ì»¨í…ìŠ¤íŠ¸ ê°œì„ ì´ í•„ìš”í•œì§€ ê²°ì •í•˜ëŠ” ë¼ìš°íŒ… í•¨ìˆ˜"""
        iteration = state.get("iteration", 0)
        complexity = state.get("complexity", "ë‹¨ìˆœ")

        # ì²« ë²ˆì§¸ ë°˜ë³µì´ê±°ë‚˜ ë³µì¡í•œ ì§ˆë¬¸ì¸ ê²½ìš° ì»¨í…ìŠ¤íŠ¸ ê°œì„ 
        if iteration == 0 or complexity in ["ì¤‘ê°„", "ë³µì¡"]:
            return "refine"
        else:
            return "generate"

    def _should_continue_route(
        self, state: CorrectiveRAGState
    ) -> Literal["continue", "end"]:
        """ê³„ì† ì§„í–‰í• ì§€ ê²°ì •í•˜ëŠ” ë¼ìš°íŒ… í•¨ìˆ˜"""
        iteration = state.get("iteration", 0)
        max_iterations = state.get("max_iterations", 3)
        is_correct = state.get("is_correct", True)
        confidence = state.get("confidence", 0.0)

        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆê±°ë‚˜ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì–»ì—ˆìœ¼ë©´ ì¢…ë£Œ
        if iteration >= max_iterations or (is_correct and confidence > 0.7):
            return "end"
        else:
            return "continue"

    def process_question(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ë©”ì„œë“œ"""
        print(f"ğŸ¤– LangGraph Corrective RAG Agentê°€ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤: '{question}'")

        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "question": question,
            "messages": [HumanMessage(content=question)],
            "analysis": None,
            "keywords": [],
            "complexity": "ë‹¨ìˆœ",
            "search_results": [],
            "context": "",
            "refined_context": "",
            "answer": "",
            "corrected_answer": "",
            "is_correct": False,
            "confidence": 0.0,
            "issues": [],
            "improvements": [],
            "iteration": 0,
            "max_iterations": self.max_iterations,
            "is_satisfactory": False,
            "should_continue": True,
            "correction_steps": [],
            "error_message": None,
        }

        # ê·¸ë˜í”„ ì‹¤í–‰
        try:
            final_state = self.graph.invoke(initial_state)

            # ê²°ê³¼ ì •ë¦¬
            result = {
                "question": question,
                "answer": final_state.get(
                    "corrected_answer", final_state.get("answer", "")
                ),
                "is_satisfactory": final_state.get("is_correct", False)
                and final_state.get("confidence", 0) > 0.7,
                "confidence": final_state.get("confidence", 0.0),
                "iterations": final_state.get("iteration", 0),
                "correction_steps": final_state.get("correction_steps", []),
                "issues": final_state.get("issues", []),
                "improvements": final_state.get("improvements", []),
                "messages": final_state.get("messages", []),
                "timestamp": datetime.now().isoformat(),
            }

            print(
                f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ - ì‹ ë¢°ë„: {result['confidence']:.2f}, ë°˜ë³µ íšŸìˆ˜: {result['iterations']}"
            )

            return result

        except Exception as e:
            print(f"âŒ ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "question": question,
                "answer": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "is_satisfactory": False,
                "confidence": 0.0,
                "iterations": 0,
                "correction_steps": [],
                "issues": [str(e)],
                "improvements": [],
                "messages": [],
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
            }
